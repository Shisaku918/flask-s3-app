import boto3
import os
import botocore
from botocore import exceptions

region = os.getenv("AWS_REGION")
bucket_name = os.getenv("AWS_BUCKET_NAME")

s3 = boto3.resource('s3', region_name=region)
s3_client = boto3.client('s3', region_name=region)
bucket = s3.Bucket(bucket_name)

def list_s3_objects(prefix=''):
    response = s3_client.list_objects_v2(
        Bucket=bucket_name,
        Prefix=prefix,
        Delimiter='/'  # Important pour simuler une structure en dossier
    )

    folders = []
    files = []

    # Gestion des sous-dossiers imm√©diats
    for cp in response.get('CommonPrefixes', []):
        folders.append(cp['Prefix'])

    # Gestion des fichiers √† ce niveau uniquement (pas dans sous-sous-dossier)
    for obj in response.get('Contents', []):
        key = obj['Key']
        if key == prefix:
            continue  # on ignore la "racine" elle-m√™me
        relative_path = key[len(prefix):]
        if '/' not in relative_path:
            files.append(relative_path)

    return folders, files



def upload_file(local_path, stocking_folder): #local_path = l√† o√π se trouve le fichier √† upload et stocking_folder = l√† o√π il faut le stocker
    filename = os.path.basename(local_path)
    stocking_path = f"{stocking_folder}/{filename}"

    try:
        bucket.upload_file(local_path, stocking_path)
        return True, "Fichier upload√© avec succ√®s"
    except Exception as e:
        return False, f"Erreur : {e}"


def download_file(key, filename): #key = chemin du fichier √† download et filename = o√π le stocker

    try:
            bucket.download_file(key, filename)
            return True, "Le fichier a √©t√© t√©l√©charg√© avec succ√®s !"
    except Exception as e:
        return False, f"Erreur lors du t√©l√©chargement : {e}"


def remove(key):
    try:
        if key.endswith('/'):
            # üîç √âtape 1 : lister tous les objets dans ce "dossier"
            objects_to_delete = bucket.objects.filter(Prefix=key)
            keys = [{'Key': obj.key} for obj in objects_to_delete]

            # üîç √âtape 2 : si aucun objet trouv√©, tenter suppression du dossier vide
            if not keys:
                try:
                    # Peut-√™tre qu‚Äôun objet vide 'prefix/' existe ?
                    s3.Object(bucket_name, key).load()
                    s3.Object(bucket_name, key).delete()
                    return True, f"Dossier vide supprim√© avec succ√®s : {key}"
                except botocore.exceptions.ClientError as e:
                    if e.response['Error']['Code'] == '404':
                        return False, "Ce dossier est d√©j√† vide et n'existe pas en tant qu'objet."
                    else:
                        raise  # Autre erreur ‚Üí on relance
            else:
                # ‚úÇÔ∏è √âtape 3 : supprimer tous les objets
                response = bucket.delete_objects(Delete={'Objects': keys})
                deleted = response.get('Deleted', [])
                return True, f"{len(deleted)} objets supprim√©s dans le dossier '{key}'."

        else:
            # üóëÔ∏è Suppression d'un fichier
            s3.Object(bucket_name, key).delete()
            return True, f"Fichier supprim√© avec succ√®s : {key}"

    except Exception as e:
        return False, f"Erreur lors de la suppression : {e}"




def copy(source_key, dest_key):
    try:
        if source_key.endswith('/'):  # parce que les dossiers finissent en /
            objects_to_copy = list(bucket.objects.filter(Prefix=source_key))  # sourceKey + /
            if not objects_to_copy:
                return  "Aucun objet trouv√© √† ce chemin source."

            for obj in objects_to_copy:
                new_key = dest_key + obj.key[len(source_key):]
                # permet de r√©cup√©rer ce qu'il y a apr√®s la source key en gros :
                # len(source_key) sert √† enlever la partie commune du chemin de source et le obj.key[len(source_key):]
                # sert donc simplement √† donner ce qu'il y a apr√®s le pr√©fixe source afin de copier coller directement sous la nouvelle destination.
                copy_source = {'Bucket': bucket_name,
                               'Key': obj.key}  # dico qui sert √† indiquer quelle est la source √† copier (quel bucket et quelle cl√© (chemin)
                s3.Object(bucket_name, new_key).copy(
                    copy_source)  # effectue la copie en se servant de la nouvelle cl√© cr√©√©e depuis la source
            return f"{len(objects_to_copy)} objets copi√©s avec succ√®s."
        else:
            copy_source = {'Bucket': bucket_name, 'Key': source_key}
            s3.Object(bucket_name, dest_key).copy(copy_source)
            return "Fichier copi√© avec succ√®s."
    except Exception as e:
        return f"Erreur lors de la copie : {e}"


def rename(key, renamed_key):
    if key.endswith('/') and not renamed_key.endswith('/'):
        renamed_key += '/'

    copy_result = copy(key, renamed_key)
    if isinstance(copy_result, str) and "Erreur" in copy_result:
        return False, f"Erreur pendant la copie : {copy_result}"

    remove_result, msg = remove(key)
    if not remove_result:
        return False, f"Copi√© mais erreur pendant la suppression : {msg}"

    return True, f"L'√©l√©ment {key} a √©t√© renomm√© {renamed_key} avec succ√®s !"


def move(source_key, dest_key):
    try:
        # Appelle ta fonction copy
        copy_result = copy(source_key, dest_key)
        if isinstance(copy_result, str) and "Erreur" in copy_result:
            return False, f"Erreur pendant la copie : {copy_result}"

        # Supprime la source (fichier ou dossier)
        remove_result, msg = remove(source_key)
        if not remove_result:
            return False, f"Copi√© mais erreur lors de la suppression : {msg}"

        return True, f"{source_key} d√©plac√© vers {dest_key} avec succ√®s !"

    except Exception as e:
        return False, f"Erreur pendant le d√©placement : {e}"


def get_parent_prefix(prefix):
    if not prefix:
        return None
    parts = prefix.rstrip('/').split('/')
    if len(parts) <= 1:
        return ''
    return '/'.join(parts[:-1]) + '/'


def get_folders_and_files(prefix):
    paginator = s3_client.get_paginator('list_objects_v2')
    result = paginator.paginate(Bucket=bucket_name, Prefix=prefix, Delimiter='/')

    folders = []
    files = []

    for page in result:
        # Les dossiers "communs" sont dans CommonPrefixes
        if 'CommonPrefixes' in page:
            for cp in page['CommonPrefixes']:
                folders.append(cp['Prefix'])

        # Les fichiers dans Contents
        if 'Contents' in page:
            for obj in page['Contents']:
                # Exclure le dossier lui-m√™me (cl√© √©gale au prefix)
                if obj['Key'] != prefix:
                    files.append(obj['Key'])

    # Pour ne garder que le nom relatif √† ce prefix (et pas le chemin complet)
    folders = [f[len(prefix):] for f in folders]
    files = [f[len(prefix):] for f in files]

    return folders, files